{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUvzK7adoYsM",
        "outputId": "4789287a-58c5-4739-e0de-bef8f624345d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, sent_tokenize\n",
        "text = \" Ms Prisha, an avid reader, enjoys books on various subjects. \" \\\n",
        "\"Ms Prisha, innovated girl, conducts groundbreaking research.\"\n",
        "text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "CTclMIKAonk7",
        "outputId": "80e25b2e-68e6-402d-f780-5a3d492dfe48"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Ms Prisha, an avid reader, enjoys books on various subjects. Ms Prisha, innovated girl, conducts groundbreaking research.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words=text.split()\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiCnysFhpckp",
        "outputId": "f875cad8-d4d1-4072-fb97-1847026c17d0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ms',\n",
              " 'Prisha,',\n",
              " 'an',\n",
              " 'avid',\n",
              " 'reader,',\n",
              " 'enjoys',\n",
              " 'books',\n",
              " 'on',\n",
              " 'various',\n",
              " 'subjects.',\n",
              " 'Ms',\n",
              " 'Prisha,',\n",
              " 'innovated',\n",
              " 'girl,',\n",
              " 'conducts',\n",
              " 'groundbreaking',\n",
              " 'research.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1iWV3AzpidN",
        "outputId": "f7f2aa0d-fb9c-4aa6-b30e-1d09644f01e8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import statemnetd only once when running the cell\n",
        "'''import nltk\n",
        "nltk.download('punkt_tab')'''\n",
        "words = word_tokenize(text)\n",
        "words\n",
        "#len(words) prints 23\n",
        "#characters such as ',' and '.' are treated as additional characters."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we_qDhZiplOs",
        "outputId": "96bc0767-a4aa-4c93-a4d1-ff1ad78e2f6f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ms',\n",
              " 'Prisha',\n",
              " ',',\n",
              " 'an',\n",
              " 'avid',\n",
              " 'reader',\n",
              " ',',\n",
              " 'enjoys',\n",
              " 'books',\n",
              " 'on',\n",
              " 'various',\n",
              " 'subjects',\n",
              " '.',\n",
              " 'Ms',\n",
              " 'Prisha',\n",
              " ',',\n",
              " 'innovated',\n",
              " 'girl',\n",
              " ',',\n",
              " 'conducts',\n",
              " 'groundbreaking',\n",
              " 'research',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(text)\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSjqTtJ6qEVC",
        "outputId": "81728678-e2a5-417c-a852-5e59c4a0a375"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Ms Prisha, an avid reader, enjoys books on various subjects.',\n",
              " 'Ms Prisha, innovated girl, conducts groundbreaking research.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq9p3CLVqKpY",
        "outputId": "7a1de9ba-85b0-42dd-cb76-360d70c28559"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Types of Tokenizer\n",
        "from nltk.tokenize import TreebankWordTokenizer, WordPunctTokenizer,WhitespaceTokenizer, TweetTokenizer\n",
        "#TreeBankTokenizer:Handles punctuations , considers them separate characters combined with the words . See example below:-\n",
        "#WordPunct:- More aggressive and spilts puntuations and words separately.\n",
        "#WhitespaceTokenizer:-Splits tokens based on whitespace and linebreaks.\n",
        "#TweetTokenizer:- breaks according to '#','!','emojis'."
      ],
      "metadata": {
        "id": "4A_tT0brquHU"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(word_tokenize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KecqdScWrLWl",
        "outputId": "b0ef3553-4da0-4312-da85-a0fbbc7dd374"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function word_tokenize in module nltk.tokenize:\n",
            "\n",
            "word_tokenize(text, language='english', preserve_line=False)\n",
            "    Return a tokenized copy of *text*,\n",
            "    using NLTK's recommended word tokenizer\n",
            "    (currently an improved :class:`.TreebankWordTokenizer`\n",
            "    along with :class:`.PunktSentenceTokenizer`\n",
            "    for the specified language).\n",
            "    \n",
            "    :param text: text to split into words\n",
            "    :type text: str\n",
            "    :param language: the model name in the Punkt corpus\n",
            "    :type language: str\n",
            "    :param preserve_line: A flag to decide whether to sentence tokenize the text or not.\n",
            "    :type preserve_line: bool\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"They'll be back at 2:30 p.m. after the quick run-around !!!\"\n",
        "text2='#NLPðŸ˜‚,ðŸ˜‚,#OPENCVðŸ¥²ðŸ¥²'\n",
        "text1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "_sMdfsu5rRMc",
        "outputId": "32b6a05a-fa8e-4b04-95b9-5630e962efe1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"They'll be back at 2:30 p.m. after the quick run-around !!!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeback_tokenizer = TreebankWordTokenizer()\n",
        "tokens=treeback_tokenizer.tokenize(text1)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS7Dn8Q8rWw7",
        "outputId": "1d704395-fa5f-430b-a598-1a9c8c560d9d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['They',\n",
              " \"'ll\",\n",
              " 'be',\n",
              " 'back',\n",
              " 'at',\n",
              " '2:30',\n",
              " 'p.m.',\n",
              " 'after',\n",
              " 'the',\n",
              " 'quick',\n",
              " 'run-around',\n",
              " '!',\n",
              " '!',\n",
              " '!']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordpunct_tokenizer=WordPunctTokenizer()\n",
        "tokens=wordpunct_tokenizer.tokenize(text1)\n",
        "tokens\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB762B32rROq",
        "outputId": "8cdb7098-f5d0-444b-b28a-5d70e6b94a03"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['They',\n",
              " \"'\",\n",
              " 'll',\n",
              " 'be',\n",
              " 'back',\n",
              " 'at',\n",
              " '2',\n",
              " ':',\n",
              " '30',\n",
              " 'p',\n",
              " '.',\n",
              " 'm',\n",
              " '.',\n",
              " 'after',\n",
              " 'the',\n",
              " 'quick',\n",
              " 'run',\n",
              " '-',\n",
              " 'around',\n",
              " '!!!']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "white_space_tokenizer=WhitespaceTokenizer()\n",
        "tokens=white_space_tokenizer.tokenize(text1)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO5UHWTkrRQ5",
        "outputId": "7f3957b4-6b6e-4968-af89-b007d30321de"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"They'll\",\n",
              " 'be',\n",
              " 'back',\n",
              " 'at',\n",
              " '2:30',\n",
              " 'p.m.',\n",
              " 'after',\n",
              " 'the',\n",
              " 'quick',\n",
              " 'run-around',\n",
              " '!!!']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_tokenizer=TweetTokenizer()\n",
        "tokens=tweet_tokenizer.tokenize(text1)\n",
        "tokens1=tweet_tokenizer.tokenize(text2)\n",
        "tokens,tokens1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp8hxjEHrRTB",
        "outputId": "8893fdd0-1f19-4b1c-ae10-017784daca8c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([\"They'll\",\n",
              "  'be',\n",
              "  'back',\n",
              "  'at',\n",
              "  '2:30',\n",
              "  'p',\n",
              "  '.',\n",
              "  'm',\n",
              "  '.',\n",
              "  'after',\n",
              "  'the',\n",
              "  'quick',\n",
              "  'run-around',\n",
              "  '!',\n",
              "  '!',\n",
              "  '!'],\n",
              " ['#NLP', 'ðŸ˜‚', ',', 'ðŸ˜‚', ',', '#OPENCV', 'ðŸ¥²', 'ðŸ¥²'])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#types of sentence tokenizer\n",
        "from nltk.tokenize import PunktSentenceTokenizer, RegexpTokenizer, BlanklineTokenizer,LineTokenizer\n",
        "#sentences\n",
        "sentence1 =\"Hello! How are you? I'm learning NLP.\"\n",
        "sentence = sent_tokenize(sentence1)\n",
        "sentence\n",
        "\n",
        "#PunktSentenceTokenizer:unsupervised sentence tokenizer\n",
        "#Regexp(Regular expression)Tokenizer:- for emails which have characters such as @\n",
        "#LineTokenizer:- separated by linebreak or new line\n",
        "#BlankLineTokenizer:- separates by blank line\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_JqXuV_rRVJ",
        "outputId": "9a8da1cc-0709-4076-bb6c-5b85541d6e87"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello!', 'How are you?', \"I'm learning NLP.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "email= \"My email is radharay59@gmail.com and contact is +91-1234-567-890\"\n",
        "regexp_tokenizer = RegexpTokenizer(r'\\w+')\n",
        "tokens = regexp_tokenizer.tokenize(email)\n",
        "tokens\n",
        "#(\\w for words , + for one or many characters, rs is raw string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqh8cHS8rRYB",
        "outputId": "769117e9-1190-4196-a675-d5652addbe9e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My',\n",
              " 'email',\n",
              " 'is',\n",
              " 'radharay59',\n",
              " 'gmail',\n",
              " 'com',\n",
              " 'and',\n",
              " 'contact',\n",
              " 'is',\n",
              " '91',\n",
              " '1234',\n",
              " '567',\n",
              " '890']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#line tokenizer\n",
        "text = \"\"\"This is the first line.\n",
        "This is the second line.\n",
        "\n",
        "This is the fourth line.\"\"\"\n",
        "\n",
        "blankline_tokenizer = BlanklineTokenizer()\n",
        "tokens = blankline_tokenizer.tokenize(text)\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PryK5KPRrRaZ",
        "outputId": "ae807b33-5c49-45b7-c416-01551a58df82"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This is the first line.\\nThis is the second line.', 'This is the fourth line.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is the first line.\\nThis is the second line.\\n This is the third line.\"\n",
        "\n",
        "line_tokenizer = LineTokenizer()\n",
        "tokens = line_tokenizer.tokenize(text)\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqgzuSb1zWeO",
        "outputId": "b6e79ace-3aa8-48e2-b174-697a4737bb57"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This is the first line.', 'This is the second line.', ' This is the third line.']\n"
          ]
        }
      ]
    }
  ]
}